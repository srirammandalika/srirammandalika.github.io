<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta name=viewport content="width=800">
    <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
    <link href='https://fonts.googleapis.com/css?family=Titillium Web' rel='stylesheet'>
    <style type="text/css">
    /* Design Credits: Jon Barron and Abhishek Kar and Saurabh Gupta*/
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 400
    }
    heading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 19px;
      font-weight: 1000
    }
    strong {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 16px;
      font-weight: 1200
    }
    strongred {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      color: 'red' ;
      font-size: 16px
    }
    sectionheading {
      font-family: 'Titillium Web', Verdana, Helvetica, sans-serif;
      font-size: 22px;
      font-weight: 600
    }
    </style>
  <link rel="shortcut icon" type="image/png" href="images/MLogo.png" />
  <script type="text/javascript" src="js/hidebib.js"></script>
  <title>Sriram Mandalika</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <table width="900" border="0" align="center" cellspacing="0" cellpadding="20">
    <tr>
        <td halign="center">
          <p align="center">
            <font size="6">Annapoorna Sai Sriram Mandalika</font>
          </p>
        </td>
      </tr>
    <tr>
    <td>
      <table width="100%" ,align="center" ,border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="70%" valign="middle">
        <p>I am a research focused Third-year Undergrad at <a href="https://www.srmist.edu.in/">SRM Institute of Science and Technology</a> Chennai and a research collaborator at <a href="https://ckmvigil.in">VIGI Lab @ IIT Hyderabad</a>. I work with Dr. <a href="https://www.srmist.edu.in/faculty/dr-athira-m-nambiar/">Athira M. Nambiar</a> and Prof. <a href="https://people.iith.ac.in/ckm/">C. Krishna Mohan @IITH</a>. My research focus is on building effecient paradigm specific algorithms using Deep Learning for Computer Vision applications.

      <!--  <p>I got my PhD in Computer Science at UIUC working with Prof. <a href="http://www.alexander-schwing.de/">Alex&nbsp;Schwing</a> and Prof.&nbsp;<a href="http://slazebni.cs.illinois.edu/">Svetlana&nbsp;Lazebnik</a>. -->
          <!-- . I built social embodied agents that can collaborate and communicate in virtual visual worlds. -->
        </p>
      
      <!--  <p>Earlier, I graduated from <a href="http://www.iitk.ac.in/">IIT&nbsp;Kanpur</a> where I worked with Prof. <a href="https://www.cse.iitk.ac.in/users/vinaypn/">Vinay&nbsp;Namboodiri</a> and Prof. <a href="https://people.cs.umass.edu/~elm/">Erik&nbsp;Learned-Miller</a>.
          <!-- and <a href="http://people.cs.umass.edu/~smaji/">Subhransu Maji</a> that I stepped into the wonderful field of Computer Vision.</p> -->
        <!--<p></p>-->
            <p align="center"><a>
      </a><a href="Data/Res 2.pdf">CV</a> | </a><a href=mailto:mc9991@srmist.edu.in>E-Mail</a> | <a href="https://www.linkedin.com/in/srirammandalika/">LinkedIn</a> | <a href="https://github.com/srirammandalika">Github</a> <!--| <a href="https://twitter.com/unnatjain2010"> Twitter</a> -->
<!--            | <a href="https://unnatj.github.io"> Bday spoof</a>-->
      </p>

        <!-- <p align=center>
          <a href="mailto:uj2@illinois.com"><i class="fa fa fa-bank fa-2x" aria-hidden="true"></i></a> &nbsp &nbsp
		  <a href="mailto:unnatjain@gmail.com"><i class="fa fa-envelope fa-2x" aria-hidden="true"></i></a> &nbsp &nbsp
		  <a href="https://scholar.google.com/citations?user=UhdfONIAAAAJ&hl=en"><i class="fa fa-mortar-board fa-2x" aria-hidden="true"></i></a> &nbsp &nbsp 
         
          <a href="https://www.linkedin.com/in/unnat-jain-559175101/"><i class="fa fa-linkedin fa-2x" aria-hidden="true"></i> </a> &nbsp &nbsp 
		 <a href="https://github.com/unnat"><i class="fa fa-github fa-2x" aria-hidden="true"></i> </a>
        </p> -->
        </td>
        <td width="100%" valign="top">
        <img src="images/My_SLF.png" width="100%">
        </td>
      </tr>
      </table>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody>
      <tr>
        <td>
        <heading>Affiliations</heading>
        </td>
      </tr>
      </tbody>
    </table>
    <table align="center">
        <tbody>
        <tr>
            <td width="22%" align="center">
                <a href="https://www.srmist.edu.in" target="_blank">
                <img style="width:80px"  src="images/srm.png"></a>&nbsp &nbsp
            </td>
            <td width="22%" align="center">
                <a href="https://www.iith.ac.in" target="_blank">
                <img style="width:80px"  src="images/IIT_H.png"></a>&nbsp &nbsp
          <!--  </td>
            <td width="22%" align="center">
                <a href="https://cs.illinois.edu/" target="_blank">
                <img style="width:100px" src="unnat_jain_files/uiuc2.jpg"></a>&nbsp &nbsp
            </td>
            <td width="24%" align="center">
                <a href="https://research.fb.com/category/facebook-ai-research/" target="_blank">
                <img style="width:150px" src="unnat_jain_files/postdoc_2.png"></a>&nbsp &nbsp
            </td> -->
        </tr>
        <tr>
            <td width="22%" align="center"><font size="2">SRM IST<br>2021-2025</font></td>
            <td width="22%" align="center"><font size="2">IIT Hyderabad<br>Summer 2022, 2023</font></td>
          <!--  <td width="22%" align="center"><font size="2">UIUC <br>2016-2022</font></td>
            <td width="22%" align="center"><font size="2">FAIR (collab. w/ CMU) <br>2022-present</font></td> -->
        </tr>
        </tbody>
    </table>
    <br>
    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tbody>
      <tr>
        <td>
        <heading>Internships</heading>
        </td>
      </tr>
      </tbody>
    </table>
    <table align="center" >
        <tbody>
        <tr>
            <td width="23%" align="center">
                <a href="https://www.iith.ac.in" target="_blank">
                <img style="width:100px" src="images/IIT_H.png"></a>&nbsp &nbsp
            </td>
          <!--  <td width="22%" align="center">
                <a href="https://prior.allenai.org/" target="_blank">
                <img style="width:60px" src="unnat_jain_files/ai2_2.png"></a>&nbsp &nbsp
            </td>
            <td width="24%" align="center">
                <a href="https://research.fb.com/category/facebook-ai-research/" target="_blank">
                <img style="width:150px" src="unnat_jain_files/fair_ut_2.png"></a>&nbsp &nbsp
            </td>
            <td width="27%" align="center">
                <a href="http://deepmind.com/" target="_blank">
                <img style="width:160px" src="unnat_jain_files/deepmind_2.png"></a>&nbsp &nbsp
            </td> -->
        </tr>
        <tr>
            <td width="24%" align="center"><font size="2">IIT Hyderabad<br>Summer 2022, 2023</font></td>
          <!--  <td width="24%" align="center"><font size="2">Allen Institute for AI<br>Summer 2018, 2020</font></td>
            <td width="24%" align="center"><font size="2">FAIR (collab w/ UT Austin)<br>Summer 2019, FA19, SP20</font></td>
            <td width="24%" align="center"><font size="2">Google DeepMind<br>Summer 2021, FA21</font></td> -->
        </tr>
        </tbody>
    </table>
    <br>

    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>News</heading>
        </td>
      </tr>
      </table>	  
	  <table class="news-table" width="100%" align="center" border="0"     style="text-align: justify">
    <colgroup><col width="15%">
    <col width="85%">
    </colgroup><tbody>
    <tr>
        <td valign="top" align="center"><strong>July 2023</strong></td>
        <td>Starting working as a Research Collaborator at IIT Hyderabad.</td>
    </tr>
      <tr>
        <td valign="top" align="center"><strong>Mar 2023</strong></td>
        <td>Started working as an Undergraduate Researcher at AI Robotics Lab, SRM Institute of Science and Technology, Kattankulathur.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Dec 2022</strong></td>
        <td>I have started working as an Undergraduate Researcher at SRM Institute of Science and Technology, Kattankulathur.</td>
    </tr>
    <!--<tr>
      <td valign="top" align="center"><strong>Dec 2022</strong></td>
      <td>Taking charge as Head of Research & Development at IEEE SRMIST.</td>
    </tr>
    <tr>
      <td valign="top" align="center"><strong>Sep 2022</strong></td>
      <td>Serving as Area Chair for CVPR 2023.</td>
    </tr>
    <!-- <tr>
      <td valign="top" align="center"><strong>Aug 2022</strong></td>
      <td>In 2022, <a href="https://github.com/HimangiM/RepLAI">RepLAI</a> accepted at NeurIPS, <a href="https://jbwasse2.github.io/portfolio/SLING/">SLING</a> at CoRL, and survey on <a href="https://arxiv.org/pdf/2210.06849">Retrospectives of Embodied AI</a> released.</td>
    </tr>   
    <tr>
      <td valign="top" align="center"><strong>Mar 2022</strong></td>
      <td> Started at Meta AI & CMU w/ Abhinav, Deepak, and Xinlei -- diving into embodied learning (from & for humans), representations, and robotics.</td> -->
    </tr>  
  </tbody></table>

  <a href="javascript:toggleblock('news')">+ Older News</a>

  <div id="news" style="display:none">
  <table id="news-extra" class="news-table" width="100%" align="center" border="0"     style="text-align: justify">
  <colgroup><col width="15%">
  <col width="85%">
  </colgroup>
  <tbody>
    <tr>
        <td valign="top" align="center"><strong>Oct 2021</strong></td>
        <td>Nov 2022, I am actively seeking research opportunities to work on computer vision problems involving self-supervised learning-based approaches.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>May 2020</strong></td>
        <td> Summer #2 at <a href="http://allenai.org/">Allen Institute for Artificial Intelligence</a>, Seattle.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Dec 2019</strong></td>
        <td>Released <a href="https://arxiv.org/pdf/1912.11474.pdf"> AV Embodied Navigation preprint</a> (intern work at Facebook AI Research).</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Nov 2019</strong></td>
        <td> NeurIPS camera ready, code, and slides for <strong>TAB-VCR</strong> are up on <a href="https://deanplayerljx.github.io/tabvcr/">project page</a>!</td>
    </tr>
    <!--<tr>-->
        <!--<td valign="top" align="center"><strong>Sep 2019</strong></td>-->
        <!--<td> <a href="https://www.linkedin.com/in/jingxiang-dean-lin-45ba18126">Jingxiang (Dean) Lin</a>'s <strong>TAB-VCR</strong> accepted at NeurIPS 2019, camera ready coming soon!</td>-->
    <!--</tr>
    <tr>
        <td valign="top" align="center"><strong>May 2019</strong></td>
        <td> Summer at <a href="https://research.fb.com/category/facebook-ai-research/">Facebook AI Research</a>, Menlo Park.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Mar 2019</strong></td>
        <td> Named <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/2019-north-america">Qualcomm Innovation Fellowship 2019</a> Finalists.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Feb 2019</strong></td>
        <td> Awarded best presenter at AI session of <a href="https://publish.illinois.edu/cslstudentconference2019/technical-sessions/ai/">CSL student conference 2019</a>.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Nov 2018</strong></td>
        <td> <a href="https://www.ideals.illinois.edu/bitstream/handle/2142/101574/JAIN-THESIS-2018.pdf?sequence=1&isAllowed=y">MS thesis</a> selected for David J. Kuck outstanding MS thesis award 2019. [<a href="https://cs.illinois.edu/about-us/awards/alumni-awards/top-alumni-and-faculty-honored-their-achievements">CS News</a>]</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>May 2018</strong></td>
        <td> Summer at <a href="http://allenai.org/">Allen Institute for Artificial Intelligence</a>, Seattle.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Apr 2018</strong></td>
        <td> Accepted UIUC's Ph.D. offer. Will begin fall'18!</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Feb 2017</strong></td>
        <td> <a href="https://arxiv.org/pdf/1803.11186.pdf">Paper</a> on two sided evaluation of visual dialog got accepted to CVPR 2018</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Sep 2017</strong></td>
        <td> Received <a href="http://www.siebelscholars.com/about">Siebel Scholar Award</a> 2017 by Thomas and Stacey Siebel foundation [<a href="https://cs.illinois.edu/news/top-cs-illinois-students-named-2018-siebel-scholars">CS News</a>]</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>May 2017</strong></td>
        <td> Summer at <a href="https://www.uber.com/info/atg/">Uber ATG (self-driving)</a>, Pittsburgh.</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>May 2017</strong></td>
        <td> Received <a href="http://cvpr2017.thecvf.com/files/CVPR_Student_Volunteer.pdf">Student volunteer award</a> from CVF and conference travel grant from UIUC for CVPR 2017.</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>Mar 2017</strong></td>
        <td> <a href="https://arxiv.org/pdf/1709.08103.pdf">Paper</a> accepted to Conference on Computer and Robot Vision (CRV) 2017 based on IIT Kanpur's thesis.</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>Jan 2017</strong></td>
        <td> <a href="https://arxiv.org/pdf/1704.03493.pdf">Paper</a> accepted at CVPR 2017 as <a href="https://www.youtube.com/watch?v=i8joIhgMiug">spotlight presentation</a>!</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>Jul 2016</strong></td>
        <td>Received Director's Gold Medal and Cadence Gold Medal from IIT Kanpur for best all-rounder and best thesis, respectively.</td>
    </tr> -->

    <!--
    </tr>
    <tr>
        <td valign="top" align="center"><strong>May 2020</strong></td>
        <td> Summer #2 at <a href="http://allenai.org/">Allen Institute for Artificial Intelligence</a>, Seattle.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Dec 2019</strong></td>
        <td>Released <a href="https://arxiv.org/pdf/1912.11474.pdf"> AV Embodied Navigation preprint</a> (intern work at Facebook AI Research).</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Nov 2019</strong></td>
        <td> NeurIPS camera ready, code, and slides for <strong>TAB-VCR</strong> are up on <a href="https://deanplayerljx.github.io/tabvcr/">project page</a>!</td>
    </tr> -->
    <!--<tr>-->
        <!--<td valign="top" align="center"><strong>Sep 2019</strong></td>-->
        <!--<td> <a href="https://www.linkedin.com/in/jingxiang-dean-lin-45ba18126">Jingxiang (Dean) Lin</a>'s <strong>TAB-VCR</strong> accepted at NeurIPS 2019, camera ready coming soon!</td>-->
    <!--</tr>
    <tr>
        <td valign="top" align="center"><strong>May 2019</strong></td>
        <td> Summer at <a href="https://research.fb.com/category/facebook-ai-research/">Facebook AI Research</a>, Menlo Park.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Mar 2019</strong></td>
        <td> Named <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/2019-north-america">Qualcomm Innovation Fellowship 2019</a> Finalists.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Feb 2019</strong></td>
        <td> Awarded best presenter at AI session of <a href="https://publish.illinois.edu/cslstudentconference2019/technical-sessions/ai/">CSL student conference 2019</a>.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Nov 2018</strong></td>
        <td> <a href="https://www.ideals.illinois.edu/bitstream/handle/2142/101574/JAIN-THESIS-2018.pdf?sequence=1&isAllowed=y">MS thesis</a> selected for David J. Kuck outstanding MS thesis award 2019. [<a href="https://cs.illinois.edu/about-us/awards/alumni-awards/top-alumni-and-faculty-honored-their-achievements">CS News</a>]</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>May 2018</strong></td>
        <td> Summer at <a href="http://allenai.org/">Allen Institute for Artificial Intelligence</a>, Seattle.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Apr 2018</strong></td>
        <td> Accepted UIUC's Ph.D. offer. Will begin fall'18!</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Feb 2017</strong></td>
        <td> <a href="https://arxiv.org/pdf/1803.11186.pdf">Paper</a> on two sided evaluation of visual dialog got accepted to CVPR 2018</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Sep 2017</strong></td>
        <td> Received <a href="http://www.siebelscholars.com/about">Siebel Scholar Award</a> 2017 by Thomas and Stacey Siebel foundation [<a href="https://cs.illinois.edu/news/top-cs-illinois-students-named-2018-siebel-scholars">CS News</a>]</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>May 2017</strong></td>
        <td> Summer at <a href="https://www.uber.com/info/atg/">Uber ATG (self-driving)</a>, Pittsburgh.</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>May 2017</strong></td>
        <td> Received <a href="http://cvpr2017.thecvf.com/files/CVPR_Student_Volunteer.pdf">Student volunteer award</a> from CVF and conference travel grant from UIUC for CVPR 2017.</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>Mar 2017</strong></td>
        <td> <a href="https://arxiv.org/pdf/1709.08103.pdf">Paper</a> accepted to Conference on Computer and Robot Vision (CRV) 2017 based on IIT Kanpur's thesis.</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>Jan 2017</strong></td>
        <td> <a href="https://arxiv.org/pdf/1704.03493.pdf">Paper</a> accepted at CVPR 2017 as <a href="https://www.youtube.com/watch?v=i8joIhgMiug">spotlight presentation</a>!</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>Jul 2016</strong></td>
        <td>Received Director's Gold Medal and Cadence Gold Medal from IIT Kanpur for best all-rounder and best thesis, respectively.</td>
    </tr> 
    </tr>
    <tr>
        <td valign="top" align="center"><strong>May 2020</strong></td>
        <td> Summer #2 at <a href="http://allenai.org/">Allen Institute for Artificial Intelligence</a>, Seattle.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Dec 2019</strong></td>
        <td>Released <a href="https://arxiv.org/pdf/1912.11474.pdf"> AV Embodied Navigation preprint</a> (intern work at Facebook AI Research).</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Nov 2019</strong></td>
        <td> NeurIPS camera ready, code, and slides for <strong>TAB-VCR</strong> are up on <a href="https://deanplayerljx.github.io/tabvcr/">project page</a>!</td>
    </tr> -->
    <!--<tr>-->
        <!--<td valign="top" align="center"><strong>Sep 2019</strong></td>-->
        <!--<td> <a href="https://www.linkedin.com/in/jingxiang-dean-lin-45ba18126">Jingxiang (Dean) Lin</a>'s <strong>TAB-VCR</strong> accepted at NeurIPS 2019, camera ready coming soon!</td>-->
    <!--</tr>
    <tr>
        <td valign="top" align="center"><strong>May 2019</strong></td>
        <td> Summer at <a href="https://research.fb.com/category/facebook-ai-research/">Facebook AI Research</a>, Menlo Park.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Mar 2019</strong></td>
        <td> Named <a href="https://www.qualcomm.com/invention/research/university-relations/innovation-fellowship/2019-north-america">Qualcomm Innovation Fellowship 2019</a> Finalists.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Feb 2019</strong></td>
        <td> Awarded best presenter at AI session of <a href="https://publish.illinois.edu/cslstudentconference2019/technical-sessions/ai/">CSL student conference 2019</a>.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Nov 2018</strong></td>
        <td> <a href="https://www.ideals.illinois.edu/bitstream/handle/2142/101574/JAIN-THESIS-2018.pdf?sequence=1&isAllowed=y">MS thesis</a> selected for David J. Kuck outstanding MS thesis award 2019. [<a href="https://cs.illinois.edu/about-us/awards/alumni-awards/top-alumni-and-faculty-honored-their-achievements">CS News</a>]</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>May 2018</strong></td>
        <td> Summer at <a href="http://allenai.org/">Allen Institute for Artificial Intelligence</a>, Seattle.</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Apr 2018</strong></td>
        <td> Accepted UIUC's Ph.D. offer. Will begin fall'18!</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Feb 2017</strong></td>
        <td> <a href="https://arxiv.org/pdf/1803.11186.pdf">Paper</a> on two sided evaluation of visual dialog got accepted to CVPR 2018</td>
    </tr>
    <tr>
        <td valign="top" align="center"><strong>Sep 2017</strong></td>
        <td> Received <a href="http://www.siebelscholars.com/about">Siebel Scholar Award</a> 2017 by Thomas and Stacey Siebel foundation [<a href="https://cs.illinois.edu/news/top-cs-illinois-students-named-2018-siebel-scholars">CS News</a>]</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>May 2017</strong></td>
        <td> Summer at <a href="https://www.uber.com/info/atg/">Uber ATG (self-driving)</a>, Pittsburgh.</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>May 2017</strong></td>
        <td> Received <a href="http://cvpr2017.thecvf.com/files/CVPR_Student_Volunteer.pdf">Student volunteer award</a> from CVF and conference travel grant from UIUC for CVPR 2017.</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>Mar 2017</strong></td>
        <td> <a href="https://arxiv.org/pdf/1709.08103.pdf">Paper</a> accepted to Conference on Computer and Robot Vision (CRV) 2017 based on IIT Kanpur's thesis.</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>Jan 2017</strong></td>
        <td> <a href="https://arxiv.org/pdf/1704.03493.pdf">Paper</a> accepted at CVPR 2017 as <a href="https://www.youtube.com/watch?v=i8joIhgMiug">spotlight presentation</a>!</td>
    </tr>
	<tr>
        <td valign="top" align="center"><strong>Jul 2016</strong></td>
        <td>Received Director's Gold Medal and Cadence Gold Medal from IIT Kanpur for best all-rounder and best thesis, respectively.</td>
    </tr> -->
    </tbody></table>
</div>


<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
  <tr>
    <td width="100%" valign="middle">
      <heading>Projects</heading>
    </td>
  </tr>
  </table>






  
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
<tr onmouseout="habitat3_stop()" onmouseover="habitat3_start()" >
  <td width="35%">
    <div class="one">
    <div class="two" id = 'habitat3'>
      <img src="images/FederatedLearning.png" alt="Loading!" width="100%" style="border-style: none"></img>
    </div>
    </div>
    
  </td>
  <td valign="top" width="65%">
    <p><a href="">
    <img src="images/new.png" alt="[NEW]" width="5%" style="border-style: none">
    <heading>Decentralized Deep Learning: Federated Approach for Image Classification
    </heading></a><br>
    This approach allows multiple edge devices or decentralized nodes to collaboratively train a shared model without sharing their raw data. Instead, each node independently computes updates on local data and then securely aggregates these updates to improve the global model.

The project focuses on implementing deep neural networks for image recognition tasks, leveraging federated learning to address privacy concerns by keeping data decentralized. It explores how these models can learn from distributed datasets while preserving data privacy, making them applicable in scenarios where data sharing or centralized training isn't feasible or desirable.<br>
    <br>
    <a href="">Documentation</a> | 
    <a href="">Code</a> |
    <!--<br>
    Media:
    <a href="https://techcrunch.com/2023/10/20/embodied-ai-spins-a-pen-and-helps-clean-the-living-room-in-new-research/"><img src="./unnat_jain_files/media/techcrunch-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
    <!-- <a href="https://ai.meta.com/blog/habitat-3-socially-intelligent-robots-siro/"><img src="./unnat_jain_files/media/fb-ai-blog-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a> -->
    <a href="https://siliconangle.com/2023/10/20/metas-habitat-3-0-simulates-real-world-environments-intelligent-ai-robot-training/"><img src="./unnat_jain_files/media/sa-press-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
    <a href="https://www.marktechpost.com/2023/10/26/meta-ai-introduces-habitat-3-0-habitat-synthetic-scenes-dataset-and-homerobot-3-major-advancements-in-the-development-of-social-embodied-ai-agents/"><img src="./unnat_jain_files/media/marktechpost.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
  </td>
</tr> 
<!-- <tr  onmouseout="data4robotics_stop()" onmouseover="data4robotics_start()">
  <td width="35%">
    <div class="one">
    <div class="two" id = 'data4robotics'><img src='unnat_jain_files/data4robotics.gif' alt="sym" width="100%" style="border-style: none"></div> 
    </div>
  </td> -->


  <tr onmouseout="vlamp_stop()" onmouseover="vlamp_start()" >
    <td width="35%">
      <div class="one">
      <div class="two" id = 'vlamp'><img src='unnat_jain_files/vlamp.png' alt="sym" width="100%" style="border-style: none"></div>
      </div>
      <script type="text/javascript">
      function vlamp_start() {
      document.getElementById('vlamp').style.opacity = "0.9";
      }
      function vlamp_stop() {
      document.getElementById('vlamp').style.opacity = "1";
      }
      friendly_stop()
      </script>
    </td>
    <td valign="top" width="65%">
      <p><a href="https://arxiv.org/abs/2304.09179">
      <img src="images/new.png" alt="[NEW]" width="5%" style="border-style: none">
      <heading>Pretrained Language Models as Visual Planners for Human Assistance
      </heading></a><br>
      Dhruvesh Patel, Hamid Eghbalzadeh, Nitin Kamra, Michael Louis Iuzzolino, <strong>Unnat&nbsp;Jain*</strong>, Ruta Desai*<br>
      <strong>ICCV 2023</strong><br>
      <a href="https://arxiv.org/abs/2304.09179">paper</a> |
      <a href="https://github.com/facebookresearch/vlamp">code</a> 
    </td>
  </tr>


























































    <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publications</heading>
        </td>
      </tr>
      </table>

  <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tr onmouseout="habitat3_stop()" onmouseover="habitat3_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'habitat3'>
          <img src="images/AL.png" alt="Loading!" width="100%" style="border-style: none"></img>
        </div>
        </div>
        <script type="text/javascript">
        function habitat3_start() {
        document.getElementById('habitat3').style.opacity = "0.9";
        }
        function habitat3_stop() {
        document.getElementById('habitat3').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>



      <td valign="top" width="65%">
        <p><a href="https://aihabitat.org/habitat3/">
        <img src="images/new.png" alt="[NEW]" width="5%" style="border-style: none">
        <heading>Active Semantic Segmentation for Vehicles
        </heading></a><br>
        A novel active learning mechanism for semantic segmentation for domain specific applicatiom in domains like defence, agriculture, Autonomous Vehicles etc., using Cityscapes dataset we leverage the iterative data-pipeline to improve the model accuracy using the least amount labelled images.<br>
        <strong>arXiv 2023</strong><br>
        <a href="">paper</a> | 
        <a href="">project</a> |
        <a href="">code</a>
        <br>
        Media:
        <a href=""><img src="./unnat_jain_files/media/techcrunch-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <!-- <a href="https://ai.meta.com/blog/habitat-3-socially-intelligent-robots-siro/"><img src="./unnat_jain_files/media/fb-ai-blog-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a> -->
        <a href=""><img src="./unnat_jain_files/media/sa-press-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href=""><img src="./unnat_jain_files/media/marktechpost.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
      </td>
    </tr>



 
    <tr  onmouseout="data4robotics_stop()" onmouseover="data4robotics_start()">
      <td width="35%">
        <div class="one">
        <div class="two" id = 'data4robotics'><img src='unnat_jain_files/data4robotics.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function data4robotics_start() {
        document.getElementById('data4robotics').style.opacity = "0.9";
        }
        function data4robotics_stop() {
        document.getElementById('data4robotics').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="">
        <img src="./unnat_jain_files/new.png" alt="[NEW]" width="5%" style="border-style: none">
        <heading>An Unbiased Look at Datasets for Visuo-Motor Pre-Training
        </heading></a><br>
        Sudeep Dasari, Mohan Kumar Srirama, <strong>Unnat&nbsp;Jain</strong>*, Abhinav Gupta*<br>
        <strong>CoRL 2023</strong><br>
        <a href="">project</a> |
        <a href="">pdf</a>
      </td>
    </tr>



    <!--
    <tr onmouseout="vlamp_stop()" onmouseover="vlamp_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'vlamp'><img src='unnat_jain_files/vlamp.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function vlamp_start() {
        document.getElementById('vlamp').style.opacity = "0.9";
        }
        function vlamp_stop() {
        document.getElementById('vlamp').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://arxiv.org/abs/2304.09179">
        <img src="./unnat_jain_files/new.png" alt="[NEW]" width="5%" style="border-style: none">
        <heading>Pretrained Language Models as Visual Planners for Human Assistance
        </heading></a><br>
        Dhruvesh Patel, Hamid Eghbalzadeh, Nitin Kamra, Michael Louis Iuzzolino, <strong>Unnat&nbsp;Jain*</strong>, Ruta Desai*<br>
        <strong>ICCV 2023</strong><br>
        <a href="https://arxiv.org/abs/2304.09179">paper</a> |
        <a href="https://github.com/facebookresearch/vlamp">code</a> 
      </td>
    </tr>
    <tr onmouseout="zsc_stop()" onmouseover="zsc_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'zsc'><img src='unnat_jain_files/zsc.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function zsc_start() {
        document.getElementById('zsc').style.opacity = "0.9";
        }
        function zsc_stop() {
        document.getElementById('zsc').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://github.com/facebookresearch/habitat-lab/tree/social-eai#readme">
        <img src="./unnat_jain_files/new.png" alt="[NEW]" width="5%" style="border-style: none">
        <heading>Adaptive Coordination in Social Embodied Rearrangement
        </heading></a><br>
        Andrew Szot, <strong>Unnat&nbsp;Jain</strong>, Dhruv Batra, Zsolt Kira, Ruta Desai, Akshara Rai<br>
        <strong>ICML 2023</strong><br>
        <a href="https://arxiv.org/abs/2306.00087">paper</a> | 
        <a href="https://github.com/facebookresearch/habitat-lab/tree/social-eai#readme">code</a>
      </td>
    </tr>
    <tr onmouseout="vrb_stop()" onmouseover="vrb_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'vrb'><img src='unnat_jain_files/vrb.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function vrb_start() {
        document.getElementById('vrb').style.opacity = "0.9";
        }
        function vrb_stop() {
        document.getElementById('vrb').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://robo-affordances.github.io/">
        <img src="./unnat_jain_files/new.png" alt="[NEW]" width="5%" style="border-style: none">
        <heading>Affordances from Human Videos as a Versatile Representation for Robotics
        </heading></a><br>
        Shikhar Bahl*, Russell Mendonca*, Lili Chen, <strong>Unnat&nbsp;Jain</strong>, Deepak Pathak<br>
        <strong>CVPR 2023</strong><br>
        <a href="https://arxiv.org/abs/2304.08488">paper</a> |
        <a href="https://robo-affordances.github.io/">project</a>
        <!-- <a href="https://github.com/3dlg-hcvc/rrr">code</a> -->
        <br>
      <!--   Media:
        <a href="https://www.independent.co.uk/tech/robot-ai-learn-skills-video-youtube-b2362313.html"><img src="./unnat_jain_files/media/independent-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href="https://techcrunch.com/2023/06/22/robots-learn-to-perform-chores-by-watching-youtube/"><img src="./unnat_jain_files/media/techcrunch-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href="https://www.cs.cmu.edu/news/2023/VRB_robot_tasks"><img src="./unnat_jain_files/media/scs-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href="https://www.marktechpost.com/2023/06/29/empowering-robots-with-complex-task-performance-meta-ai-develops-visual-affordance-model-using-internet-videos-of-human-behavior/"><img src="./unnat_jain_files/media/marktechpost.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
      </td>
    </tr>
    <tr onmouseout="rrr_stop()" onmouseover="rrr_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'rrr'><img src='unnat_jain_files/rrr.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function rrr_start() {
        document.getElementById('rrr').style.opacity = "0.9";
        }
        function rrr_stop() {
        document.getElementById('rrr').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://3dlg-hcvc.github.io/mopa">
        <img src="./unnat_jain_files/new.png" alt="[NEW]" width="5%" style="border-style: none">
        <heading>MOPA: Modular Object Navigation with PointGoal Agents
        </heading></a><br>
        Sonia Raychaudhuri, Tommaso Campari, <strong>Unnat&nbsp;Jain</strong>, Manolis Savva, Angel X. Chang<br>
        <strong>WACV 2024</strong><br>
        <a href="http://arxiv.org/abs/2304.03696">paper</a> |
        <a href="https://3dlg-hcvc.github.io/mopa">project</a> | 
        <a href="https://github.com/3dlg-hcvc/mopa">code</a>
      </td>
    </tr>
    <tr  onmouseout="sling_stop()" onmouseover="sling_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'sling'><img src='unnat_jain_files/sling.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function sling_start() {
        document.getElementById('sling').style.opacity = "0.9";
        }
        function sling_stop() {
        document.getElementById('sling').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://jbwasse2.github.io/portfolio/SLING/">
        <heading>Last-Mile Embodied Visual Navigation</heading></a><br>
        Justin&nbsp;Wasserman*, Karmesh&nbsp;Yadav, Girish&nbsp;Chowdhary, Abhinav&nbsp;Gupta, <strong>Unnat&nbsp;Jain*</strong><br>
        <strong>CoRL 2022</strong><br>
        <a href="https://jbwasse2.github.io/files/sling.pdf">paper</a> | 
        <a href="https://jbwasse2.github.io/portfolio/SLING/">project</a> | 
        <a href="https://github.com/Jbwasse2/SLING">code</a>
      </td>
    </tr>
    <tr onmouseout="retrospectives_stop()" onmouseover="retrospectives_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'retrospectives'><img src='unnat_jain_files/retrospectives.jpg' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function retrospectives_start() {
        document.getElementById('retrospectives').style.opacity = "0.9";
        }
        function retrospectives_stop() {
        document.getElementById('retrospectives').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://arxiv.org/abs/2210.06849">
        <heading>Retrospectives on the Embodied AI Workshop</heading></a><br>
        Matt Deitke, Dhruv Batra, Yonatan Bisk, ... <b>Unnat Jain</b> ... Luca Weihs, Jiajun Wu<br>
        <strong>arXiv 2022</strong><br>
        <a href="https://arxiv.org/pdf/2210.06849">paper</a>
        <!-- <a href="https://unnat.github.io/advisor/">project</a> | -->
        <!-- <a href="https://github.com/HimangiM/RepLAI">code</a> -->
  <!--     </td>
    </tr>
    <tr onmouseout="replai_stop()" onmouseover="replai_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'replai'><img src='unnat_jain_files/replai.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function replai_start() {
        document.getElementById('replai').style.opacity = "0.9";
        }
        function replai_stop() {
        document.getElementById('replai').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://arxiv.org/abs/2209.13583">
        <heading>Learning State-Aware Visual Representations from Audible Interactions</heading></a><br>
        Himangi Mittal, Pedro Morgado, <strong>Unnat Jain</strong>, Abhinav Gupta<br>
        <strong>NeurIPS 2022</strong><br>
        <a href="https://arxiv.org/pdf/2209.13583">paper</a> | 
        <!-- <a href="https://unnat.github.io/advisor/">project</a> | -->
  <!--       <a href="https://github.com/HimangiM/RepLAI">code</a>
      </td>
    </tr>  
    <tr  onmouseout="advisor_stop()" onmouseover="advisor_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'advisor'><img src='unnat_jain_files/advisor_2.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function advisor_start() {
        document.getElementById('advisor').style.opacity = "0.9";
        }
        function advisor_stop() {
        document.getElementById('advisor').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://unnat.github.io/advisor/">
        <heading>Bridging the Imitation Gap by Adaptive Insubordination</heading></a><br>
            Luca Weihs*, <strong>Unnat Jain*</strong>, Iou-Jen Liu, Jordi Salvador, Svetlana Lazebnik, Aniruddha Kembhavi, Alexander Schwing<br>
        <strong>NeurIPS 2021</strong><br>
        <a href="https://unnat.github.io/advisor/paper.pdf">paper</a> |
        <a href="https://unnat.github.io/advisor/">project</a> |
        <a href="https://github.com/allenai/advisor/">code</a>
      </td>
    </tr>

    <tr onmouseout="law_stop()" onmouseover="law_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'law'><img src='unnat_jain_files/law.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function law_start() {
        document.getElementById('law').style.opacity = "0.9";
        }
        function law_stop() {
        document.getElementById('law').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://3dlg-hcvc.github.io/LAW-VLNCE">
        <heading>Language-Aligned Waypoint (LAW) Supervision for Vision-and-Language Navigation in Continuous Environments</heading></a><br>
            Sonia Raychaudhuri, Saim Wani, Shivansh Patel, <strong>Unnat Jain</strong>, Angel X. Chang
            <br>
        <strong>EMNLP 2021</strong> (short)<br>
        <a href="https://arxiv.org/pdf/2109.15207.pdf">paper</a> |
        <a href="https://3dlg-hcvc.github.io/LAW-VLNCE">project</a> |
        <a href="https://github.com/3dlg-hcvc/LAW-VLNCE">code</a>
      </td>
    </tr>

    <tr  onmouseout="gridtopix_stop()" onmouseover="gridtopix_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'gridtopix'><img src='unnat_jain_files/gridtopix.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function gridtopix_start() {
        document.getElementById('gridtopix').style.opacity = "0.9";
        }
        function gridtopix_stop() {
        document.getElementById('gridtopix').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://unnat.github.io/gridtopix/">
        <heading>GridToPix: Training Embodied Agents with Minimal Supervision</heading></a><br>
            <strong>Unnat Jain</strong>, Iou-Jen Liu, Svetlana Lazebnik, Aniruddha&nbsp;Kembhavi, Luca&nbsp;Weihs*, Alexander&nbsp;Schwing*
            <br>
        <strong>ICCV 2021</strong><br>
        <a href="https://arxiv.org/pdf/2105.00931.pdf">paper</a> |
        <a href="https://unnat.github.io/gridtopix/">project</a>
      </td>
    </tr>

    <tr onmouseout="comon_stop()" onmouseover="comon_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'comon'><img src='unnat_jain_files/comon.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function comon_start() {
        document.getElementById('comon').style.opacity = "0.9";
        }
        function comon_stop() {
        document.getElementById('comon').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://shivanshpatel35.github.io/comon/">
        <heading>Interpretation of Emergent Communication in Heterogeneous Collaborative Embodied Agents</heading></a><br>
            Shivansh&nbsp;Patel*, Saim&nbsp;Wani*, <strong>Unnat&nbsp;Jain*</strong>, Alexander&nbsp;Schwing, Svetlana&nbsp;Lazebnik, Manolis&nbsp;Savva, Angel&nbsp;X.&nbsp;Chang<br>
        <strong>ICCV 2021</strong><br>
        <a href="https://arxiv.org/pdf/2110.05769.pdf">paper</a> |
        <a href="https://shivanshpatel35.github.io/comon/">project</a> |
        <a href="https://github.com/saimwani/CoMON">code</a>
      </td>
    </tr>

    <tr onmouseout="cmae_stop()" onmouseover="cmae_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'cmae'><img src='unnat_jain_files/cmae.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function cmae_start() {
        document.getElementById('cmae').style.opacity = "0.9";
        }
        function cmae_stop() {
        document.getElementById('cmae').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://ioujenliu.github.io/CMAE/">
        <heading>Cooperative Exploration for Multi-Agent Deep Reinforcement Learning</heading></a><br>
            Iou-Jen Liu, <strong>Unnat Jain</strong>, Raymond Yeh, Alexander&nbsp;Schwing
            <br>
        <strong>ICML 2021 <em>(long oral)</em></strong><br>
        <a href="https://unnat.github.io/files/cmae/paper.pdf">paper</a> |
        <a href="https://ioujenliu.github.io/CMAE/">project</a> |
        <a href="https://github.com/IouJenLiu/CMAE/tree/main">code</a>
      </td>
    </tr>

    <tr onmouseout="multion_stop()" onmouseover="multion_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'multion'><img src='unnat_jain_files/multion.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function multion_start() {
        document.getElementById('multion').style.opacity = "0.9";
        }
        function multion_stop() {
        document.getElementById('multion').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://shivanshpatel35.github.io/multi-ON/">
        <heading>MultiON: Benchmarking Semantic Map Memory using Multi-Object Navigation</heading></a><br>
            Saim Wani*, Shivansh Patel*, <strong>Unnat Jain*</strong>, Angel X. Chang, Manolis Savva<br>
        <strong>NeurIPS 2020</strong><br>
        <a href="https://shivanshpatel35.github.io/multi-ON/resources/MultiON.pdf">paper</a> |
        <a href="https://shivanshpatel35.github.io/multi-ON/">project</a> |
        <a href="https://github.com/saimwani/multiON">code</a> |
        <a href="http://multion-challenge.cs.sfu.ca/">challenge</a>

      </td>
    </tr>

    <tr onmouseout="allenact_stop()" onmouseover="allenact_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'allenact' align="center"><img src='unnat_jain_files/allenact.jpg' alt="sym" width="80%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function allenact_start() {
        document.getElementById('allenact').style.opacity = "0.9";
        }
        function allenact_stop() {
        document.getElementById('allenact').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://allenact.org/">
        <heading>AllenAct: A Framework for Embodied AI Research</heading></a><br>
            Luca Weihs*, Jordi Salvador*, Klemen Kotar*, <strong>Unnat Jain</strong>, Kuo-Hao Zeng, Roozbeh Mottaghi, Aniruddha Kembhavi<br>
        <strong>arXiv 2020</strong><br>
        <a href="https://arxiv.org/pdf/2008.12760.pdf">paper</a> |
        <a href="https://allenact.org/">project</a> |
        <a href="https://github.com/allenai/allenact/">code</a>
        <br>
        Media:
        <a href="https://venturebeat.com/2020/08/31/allen-institute-open-sources-allenact-a-framework-for-research-in-embodied-ai/"><img src="./unnat_jain_files/media/venture-beat-logo.png" alt="[NEW]" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href="https://www.hackster.io/news/bet-you-can-t-do-that-again-6fc341d01fbd/"><img src="./unnat_jain_files/media/hackster-logo.png" alt="[NEW]" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href="https://analyticsindiamag.com/how-open-sourcing-allenact-provides-a-substantial-growth-for-embodied-ai/"><img src="./unnat_jain_files/media/aim.png" alt="[NEW]" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
      </td>
    </tr>

    <tr  onmouseout="cordialsync_stop()" onmouseover="cordialsync_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'cordialsync'><img src='unnat_jain_files/cordialsync.gif' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function cordialsync_start() {
        document.getElementById('cordialsync').style.opacity = "0.9";
        }
        function cordialsync_stop() {
        document.getElementById('cordialsync').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://unnat.github.io/cordial-sync/">
        <heading>A Cordial Sync: Going Beyond Marginal Policies For Multi-Agent Embodied Tasks</heading></a><br>
            <strong>Unnat Jain</strong>*, Luca Weihs*, Eric Kolve, Ali Farhadi, Svetlana Lazebnik, Aniruddha Kembhavi, Alexander Schwing<br>
        <strong>ECCV 2020 <em>(spotlight)</em></strong><br>
        <a href="https://arxiv.org/pdf/2007.04979.pdf">paper</a> |
        <a href="https://unnat.github.io/cordial-sync/">project</a> |
        <a href="https://github.com/allenai/cordial-sync/">code</a>
      </td>
    </tr>

    <tr onmouseout="avnav_stop()" onmouseover="avnav_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'avnav'><img src='unnat_jain_files/avnav2.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function avnav_start() {
        document.getElementById('avnav').style.opacity = "0.9";
        }
        function avnav_stop() {
        document.getElementById('avnav').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://soundspaces.org/">
        <heading>SoundSpaces: Audio-Visual Navigation in 3D Environments</heading></a><br>
            Changan Chen*, <strong>Unnat Jain</strong>*, Carl Schissler, Sebastia Vicenc Amengual Gari, Ziad Al-Halah, Vamsi Krishna Ithapu, Philip Robinson, Kristen Grauman<br>
        <strong>ECCV 2020 <em>(spotlight)</em></strong><br>
        <a href="https://arxiv.org/pdf/1912.11474.pdf">paper</a> |
        <a href="https://soundspaces.org/">project</a> |
        <a href="https://github.com/facebookresearch/sound-spaces">code</a> |
        <a href="https://soundspaces.org/challenge">challenge</a>
        <br>
        Media:
        <a href="https://ai.facebook.com/blog/new-milestones-in-embodied-ai/"><img src="./unnat_jain_files/media/fb-ai-blog-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href="https://www.technologyreview.com/2020/08/21/1007523/facebook-ai-robot-assistants-hear-and-see/"><img src="./unnat_jain_files/media/mit-tech-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <br>
        <a href="https://siliconangle.com/2020/08/21/facebook-open-sources-embodied-ai-tools-advance-robotic-navigation/"><img src="./unnat_jain_files/media/sa-press-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href="https://venturebeat.com/2020/08/21/facebook-releases-tools-to-help-ai-navigate-complex-environments/"><img src="./unnat_jain_files/media/venture-beat-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href="https://www.zdnet.com/article/facebook-is-building-robots-to-help-you-find-your-ringing-phone/"><img src="./unnat_jain_files/media/zdnet-press-logo.png" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
        <a href="https://dailyfreepress.com/2021/04/15/bu-event-showcases-soundspaces-a-system-adding-audio-visual-navigation-to-artificial-intelligence/"><img src="./unnat_jain_files/media/bu.jpg" alt="media logo" height="15" style="border:1px solid #D3D3D3;" hspace="0"></a>
      </td>
    </tr>

    <tr onmouseout="neurips_2019_stop()" onmouseover="neurips_2019_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'neurips_2019'><img src='unnat_jain_files/neurips_2019.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function neurips_2019_start() {
        document.getElementById('neurips_2019').style.opacity = "0.9";
        }
        function neurips_2019_stop() {
        document.getElementById('neurips_2019').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://deanplayerljx.github.io/tabvcr/">
        <heading>TAB-VCR: Tags and Attributes based VCR Baselines</heading></a><br>
          Jingxiang Lin, <strong>Unnat Jain</strong>, Alexander Schwing<br>
        <strong>NeurIPS 2019<br></strong>
        <a href="https://arxiv.org/pdf/1910.14671.pdf">paper</a> |
        <a href="https://deanplayerljx.github.io/tabvcr/">project</a> | 
        <a href="https://github.com/Deanplayerljx/tab-vcr/">code</a>
      </td>
    </tr>

    <tr  onmouseout="cvpr_2019_stop()" onmouseover="cvpr_2019_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'cvpr_2019'><img src='unnat_jain_files/cvpr_2019_2.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function cvpr_2019_start() {
        document.getElementById('cvpr_2019').style.opacity = "0.9";
        }
        function cvpr_2019_stop() {
        document.getElementById('cvpr_2019').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://prior.allenai.org/projects/two-body-problem">
        <!--<img src="./unnat_jain_files/new.png" alt="[NEW]" width="5%" style="border-style: none">-->
      <!--   <heading>Two Body Problem: Collaborative Visual Task Completion</heading></a><br>
          <strong>Unnat Jain</strong>*, Luca Weihs*, Eric Kolve, Mohammad Rastegari, Svetlana Lazebnik, Ali Farhadi, Alexander Schwing, Aniruddha Kembhavi<br>
            <strong>CVPR 2019 <em>(oral)</em></strong> <br>
        <a href="https://arxiv.org/abs/1904.05879">paper</a> |
        <a href="https://prior.allenai.org/projects/two-body-problem">project</a> |
        <a href="https://github.com/allenai/cordial-sync/">code</a>
        <br>
        Talk @ Amazon:
        <a href="https://youtu.be/MSquz7TQJ1I">video</a>,
        <a href="https://uillinoisedu-my.sharepoint.com/:p:/g/personal/uj2_illinois_edu/EcMUrcCux2RHpahdd-OR41EBi3T2XckgwWwG4e9Dtd7kbg">ppt</a>,
        <a href="https://unnat.github.io/files/tbone/slides_two_body_problem.pdf">pdf</a>
        <!--<a href="http://unnat.github.io/papers/two-body-problem-cvpr19.pdf">pdf</a> |-->
    <!--     <br>
        Talk @ CVPR'19:
        <a href="https://youtu.be/4ppCdipSlcw">video</a>,
        <a href="https://uillinoisedu-my.sharepoint.com/:p:/g/personal/uj2_illinois_edu/Ec3ytZ-uXmtKlGP0Um6atw4BDYId_s8BqX-ESee4sg8zeQ?e=gOjewz">ppt</a>,
        <a href="https://uillinoisedu-my.sharepoint.com/:b:/g/personal/uj2_illinois_edu/EaCWrXtWO2VFudNTlDocRHABU0iXXt0MZA6IyXKJURuO5g?e=7l6bqR">pdf</a>,
        <a href="https://uillinoisedu-my.sharepoint.com/:b:/g/personal/uj2_illinois_edu/EfhsnZUnR9BKketZLngdY-YB2IZxS30XtcCgMOc62sbCQQ?e=I5Ljpg">poster</a>

      </td>
    </tr>

    <tr onmouseout="cvpr_2018_stop()" onmouseover="cvpr_2018_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'cvpr_2018'><img src='unnat_jain_files/cvpr_2018.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function cvpr_2018_start() {
        document.getElementById('cvpr_2018').style.opacity = "0.9";
        }
        function cvpr_2018_stop() {
        document.getElementById('cvpr_2018').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://arxiv.org/pdf/1803.11186.pdf">
        <heading>Two can play this Game: Visual Dialog with Discriminative Question Generation and Answering</heading></a><br>
          <strong>Unnat Jain</strong>, Svetlana Lazebnik, Alexander Schwing<br>
        <strong>CVPR 2018<br></strong>
      </td>
    </tr>

    <tr  onmouseout="cvpr_2017_stop()" onmouseover="cvpr_2017_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'cvpr_2017'><img src='unnat_jain_files/cvpr_2017.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function cvpr_2017_start() {
        document.getElementById('cvpr_2017').style.opacity = "0.9";
        }
        function cvpr_2017_stop() {cvpr_2017
        document.getElementById('cvpr_2017').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://arxiv.org/pdf/1704.03493.pdf">
        <heading>Creativity: Generating Diverse Questions using Variational Autoencoders</heading></a><br>
          <strong>Unnat Jain</strong>*, Ziyu Zhang*, Alexander Schwing<br>
        <strong>CVPR 2017 <em>(spotlight)</em></strong><br>
        <a href="https://youtu.be/i8joIhgMiug">video</a> |
        <a href="https://arxiv.org/pdf/1704.03493.pdf">paper</a>
      </td>
    </tr>

      <tr onmouseout="crv_2017_stop()" onmouseover="crv_2017_start()" >
      <td width="35%">
        <div class="one">
        <div class="two" id = 'crv_2017'><img src='unnat_jain_files/crv_2017.png' alt="sym" width="100%" style="border-style: none"></div>
        </div>
        <script type="text/javascript">
        function crv_2017_start() {
        document.getElementById('crv_2017').style.opacity = "0.9";
        }
        function crv_2017_stop() {
        document.getElementById('crv_2017').style.opacity = "1";
        }
        friendly_stop()
        </script>
      </td>
      <td valign="top" width="65%">
        <p><a href="https://arxiv.org/pdf/1709.08103.pdf">
        <heading>Compact Environment-Invariant Codes for Robust Visual Place Recognition</heading></a><br>
          <strong>Unnat Jain</strong>, Vinay Namboodiri, Gaurav Pandey<br>
        <em>Conference on Computer and Robot Vision (CRV)</em> 2017<br>
      </td>
    </tr>  -->
    

       

        
        
        
     
    </table>




    
  <!--<table width="100%" align="center" border="0" cellpadding="20">-->
      <!--<tr>-->
        <!--<td width="25%"><img src="ta.jpg" alt="numerical" width="160" height="160"></td>-->
        <!--<td width="75%" valign="center">-->
        <!--<p>-->
          <!--<a href="https://relate.cs.illinois.edu/course/cs357-f16/">-->
          <!--<papertitle>CS357 - Numerical Methods - Fall 2016 </papertitle>-->
          <!--</a>-->
          <!--<br><br>-->
          <!--<a href="https://go.illinois.edu/cs101">-->
          <!--<papertitle>CS101 - Intro to Computing - Spring 2016, Fall 2017 </papertitle>-->
          <!--</a>-->
          <!--<br>-->
        <!--</p>-->
        <!--</td>-->
      <!--</tr>-->
  <!--</table>-->

       <!--<table id="thanks" width="100%" align="center" border="0" cellspacing="0" cellpadding="20">-->
            <!--<tr>-->
              <!--<td>-->
                <!--<br>-->
                <!--<p align="right"><font size="2">-->
                  <!--<a href="http://www.cs.berkeley.edu/~barron/">(imitation is the sincerest form of flattery)</a>-->
                  <!--</font>-->
                <!--</p>-->
              <!--</td>-->
            <!--</tr>-->
          <!--</table>-->
<table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
    <tbody><tr><td><br><p align="right"><font size="2">
    Template credits: <a href="https://people.eecs.berkeley.edu/~pathak/">Deepak</a>, <a href="http://www.cs.berkeley.edu/~barron/">Jon</a>, <a href="http://www.cs.berkeley.edu/~sgupta/">Saurabh</a>, and <a href="https://abhishekdas.com/">Abhishek</a>
    </font></p></td></tr>
</tbody></table>
     
    </td>
    </tr>
  </table>
  </body>
</html>
